{
    "contents" : "#loading libs\nlibrary(\"dplyr\", lib.loc=\"D:/Program Files/R/R-devel/library\")\nlibrary(\"readr\", lib.loc=\"D:/Program Files/R/R-devel/library\")\nlibrary(\"utils\", lib.loc=\"D:/Program Files/R/R-devel/library\")\n\n\n#swapping dir to get some data\nsetwd(\"../crawler\")\n\n#importing csv (to be ignored)\n\n      # building up the filename\n    \n        #scanning ../crawler for names\n        #f_name <- list.files(\"../crawler\", pattern=\"*.csv\", full.names=FALSE) %>%\n    \n        #extracting date from f_names in numeric format -> YYMMDD\n        #gsub(pattern = \"jobs\\\\.*\\\\.csv$\",replacement = \"\", f_names) %>%\n    \n        #selecting latest dataset\n        #max(na.rm = TRUE)\n  \n      #exeptions to be considered:\n      # - YY, MM and DD shouldn't exceed current date\n      # - MM shouldn't exceed 12\n      # - DD shouldn't exceed number of days specific for a given MM\n      # solution - change string to date?\n\n\n    \n  #actual imported data without \"NA\" elements\n  pracuj_data <- read_csv(\"pracuj.csv\" , col_names = TRUE) %>%\n  filter(position != \"NA\")\n  \n  \n  # switching back to filtering directory\n  setwd(\"../Filtr\")\n  \n  # creating dictionary forjob offers selection\n  \n  #created dictionaries:\n  # - phrase_dic_eng.csv contains summary of phrases in english which determine if\n  #   the job offer belongs to data.science category\n  # - phrase_dic_pl.csv contains summary of phrases in polish which determine\n  #   if the job offer belongs to data.science category\n  # - exeptions_phrase_eng.csv, exeptions_phrase_pl.csv contain expressions which indicate job offer outside data.science industry\n  #\n  # - exeptions_words_eng.csv, exeptions_words_pl.csv -- || -- (words instead of full expressions)  \n  \n  \n  \n  # listing all avaliable dictionaries\n  f_dic_names <- list.files(\"../Filtr\", pattern=\"*.csv\", full.names=FALSE)\n  f_dic_names <- subset(f_dic_names, subset = (f_dic_names != \"pracuj_filtered.csv\" &  f_dic_names != \"jobs.csv\")) %>%\n                 as.list()\n  \n  dic_list <- list()\n  \n  \n  \n  \n  #reading all avaliable dictionaries\n  for (dic in f_dic_names) {\n   \n   \n   dic_list_i <- read_csv(paste0(dic) , col_names = TRUE)\n   dic_list <- append(dic_list, dic_list_i)  \n  }\n  \n  #creating propper vector names for phrases extraction from dictionaries to vectors\n  f_dic_names <- lapply(f_dic_names, function (x) {gsub(pattern = \"\\\\.*\\\\.csv$\",replacement = \"\", x)})\n  \n  \n  # naming vector of dictionaries names\n  names(dic_list) <- f_dic_names\n  \n  \n\n  \n\n  \n  \n# Propper filtering\n  \n# 'href' selected for filtering due to universal structure .../position-name-city\n\n  \n  # creating vector used to filter interesting offers\n  needed_complete_phrases <- unlist(dic_list[grep(pattern = \".*\\\\phrase_dic\\\\.*\", names(dic_list))], use.names = FALSE)\n  \n  # creating vector used to filter out exeptions (offers containing \"data-analyst\" etc, but not in data.science industry)\n  exeptions_phrases <- unlist(dic_list[grep(pattern = \".*exeptions_phrase\\\\.*\", names(dic_list))], use.names = FALSE)\n  \n\n\n  # filtering according to phrases normally indicating data.science industry job   \n  filtered_data <- data.frame()\n  omited_data <- data.frame()\n  for (NCP in needed_complete_phrases)  {\n    filtered_data1 <- mutate(pracuj_data, DSIndicator = grepl(paste0(\".*\",NCP,\".*\"), href) )%>% filter(DSIndicator == TRUE) \n    filtered_data <- rbind(filtered_data, filtered_data1)\n  }\n  \n   \n    omited_data <- mutate(pracuj_data, DSIndicator = grepl(paste0(\".*\",NCP,\".*\"), href) )%>%filter(DSIndicator == FALSE)\n \n    \n\n  \n  \n  # excluding offers containing phrases which indicate non-data.science affiliation \n  \n  #exeptions <- data.frame()\n  for (EP in exeptions_phrases)\n  {\n  filtered_data <- mutate(filtered_data, ExeptionIndicator = grepl(paste0(\".*\",EP,\".*\"), href) )%>% filter(ExeptionIndicator == FALSE)\n  \n  }\n  filter_excluded_data <- filter(filtered_data, ExeptionIndicator == TRUE)\n  \n  \n  \n  # removing \"Indicators\" from dataset\n  filtered_data <- select(filtered_data, -contains(\"Indicator\"))%>%arrange(desc(date))\n  omited_data <- select(omited_data, -contains(\"Indicator\"))%>%arrange(desc(date))\n  exeptions <- select(exeptions, -contains(\"Indicator\"))%>%arrange(desc(date))\n  \n  \n  # same ID killer\n  \n  #a <- duplicated(filtered_data, by = \"id\")\n  \n  #print(a)\n  \n  #filtered_data <- filtered_data[!duplicated(filtered_data, by = \"id\"),]\n  \n  \n  # writing solution to file\n  write_csv(filtered_data, \"pracuj_filtered.csv\")\n  write_csv( filter_excluded_data, \"filter_excluded_data.csv\")\n  write_csv(omited_data,  \"omited_data.csv\")\n  ",
    "created" : 1456011576833.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "637070712",
    "id" : "F0B29C66",
    "lastKnownWriteTime" : 1456011474,
    "path" : "D:/eR/MI2/pracuj/pracuj/Filtr/FiltrR.R",
    "project_path" : "FiltrR.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}